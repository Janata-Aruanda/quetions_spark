{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLvrd8JsJYti"
      },
      "outputs": [],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.3-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import findspark\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.3-bin-hadoop3\"\n",
        "\n",
        "# tornar o pyspark \"import√°vel\"\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jqW6uBpwKCgn",
        "outputId": "ea2d81ef-da77-4e47-d06d-939199c03055"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.5.3-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"quetion_two\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "dados_employee = [\n",
        "    ('1', 'John', 'Doe', 10000, '2023-01-01', 'Engineering'),\n",
        "    ('2', 'Jane', 'Smith', 12000, '2022-12-01', 'Marketing'),\n",
        "    ('3', 'Alice', 'Johnson', 12000, '2022-11-01', 'Engineering'),\n",
        "    ('4', 'Bob', 'Brown', 15000, '2021-05-01', 'Sales'),\n",
        "    ('5', 'Charlie', 'Green', 13000, '2022-03-01', 'HR'),\n",
        "    ('6', 'David', 'White', 16000, '2020-07-01', 'Engineering'),\n",
        "    ('7', 'Eve', 'Black', 14000, '2023-06-01', 'Marketing'),\n",
        "    ('8', 'Frank', 'Blue', 12000, '2022-08-01', 'Sales'),\n",
        "    ('9', 'Grace', 'Pink', 11000, '2023-02-01', 'Marketing'),\n",
        "    ('10', 'Helen', 'Yellow', 16000, '2021-12-01', 'Engineering')\n",
        "]\n",
        "\n",
        "dados_titles = [\n",
        "    ('1', 'Engineer', '2022-01-01'),\n",
        "    ('2', 'Manager', '2022-01-01'),\n",
        "    ('3', 'Engineer', '2022-01-01'),\n",
        "    ('4', 'Sales Lead', '2021-05-01'),\n",
        "    ('5', 'HR Manager', '2022-03-01'),\n",
        "    ('6', 'Senior Engineer', '2020-07-01'),\n",
        "    ('7', 'Marketing Specialist', '2023-06-01'),\n",
        "    ('8', 'Sales Associate', '2022-08-01'),\n",
        "    ('9', 'Marketing Analyst', '2023-02-01'),\n",
        "    ('10', 'Senior Engineer', '2021-12-01')\n",
        "]\n",
        "\n",
        "\n",
        "colunas_employee = ['worker_id', 'first_name', 'last_name', 'salary', 'joining_date', 'department']\n",
        "colunas_titles = ['worker_ref_id', 'worker_title', 'affected_from']\n",
        "\n",
        "\n",
        "df_employee = spark.createDataFrame(dados_employee, schema=colunas_employee)\n",
        "df_titles = spark.createDataFrame(dados_titles, schema=colunas_titles)\n",
        "\n",
        "\n",
        "print(\"--- DataFrame Employee Criado ---\")\n",
        "df_employee.show()\n",
        "\n",
        "print(\"--- Schema do DataFrame Employee ---\")\n",
        "df_employee.printSchema()\n",
        "\n",
        "print(\"--- DataFrame Titles Criado ---\")\n",
        "df_titles.show()\n",
        "\n",
        "print(\"--- Schema do DataFrame Titles ---\")\n",
        "df_titles.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVNgvKiVKrNQ",
        "outputId": "de2191a5-780d-453d-fd11-3f5c27797a84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DataFrame Employee Criado ---\n",
            "+---------+----------+---------+------+------------+-----------+\n",
            "|worker_id|first_name|last_name|salary|joining_date| department|\n",
            "+---------+----------+---------+------+------------+-----------+\n",
            "|        1|      John|      Doe| 10000|  2023-01-01|Engineering|\n",
            "|        2|      Jane|    Smith| 12000|  2022-12-01|  Marketing|\n",
            "|        3|     Alice|  Johnson| 12000|  2022-11-01|Engineering|\n",
            "|        4|       Bob|    Brown| 15000|  2021-05-01|      Sales|\n",
            "|        5|   Charlie|    Green| 13000|  2022-03-01|         HR|\n",
            "|        6|     David|    White| 16000|  2020-07-01|Engineering|\n",
            "|        7|       Eve|    Black| 14000|  2023-06-01|  Marketing|\n",
            "|        8|     Frank|     Blue| 12000|  2022-08-01|      Sales|\n",
            "|        9|     Grace|     Pink| 11000|  2023-02-01|  Marketing|\n",
            "|       10|     Helen|   Yellow| 16000|  2021-12-01|Engineering|\n",
            "+---------+----------+---------+------+------------+-----------+\n",
            "\n",
            "--- Schema do DataFrame Employee ---\n",
            "root\n",
            " |-- worker_id: string (nullable = true)\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- last_name: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            " |-- joining_date: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            "\n",
            "--- DataFrame Titles Criado ---\n",
            "+-------------+--------------------+-------------+\n",
            "|worker_ref_id|        worker_title|affected_from|\n",
            "+-------------+--------------------+-------------+\n",
            "|            1|            Engineer|   2022-01-01|\n",
            "|            2|             Manager|   2022-01-01|\n",
            "|            3|            Engineer|   2022-01-01|\n",
            "|            4|          Sales Lead|   2021-05-01|\n",
            "|            5|          HR Manager|   2022-03-01|\n",
            "|            6|     Senior Engineer|   2020-07-01|\n",
            "|            7|Marketing Specialist|   2023-06-01|\n",
            "|            8|     Sales Associate|   2022-08-01|\n",
            "|            9|   Marketing Analyst|   2023-02-01|\n",
            "|           10|     Senior Engineer|   2021-12-01|\n",
            "+-------------+--------------------+-------------+\n",
            "\n",
            "--- Schema do DataFrame Titles ---\n",
            "root\n",
            " |-- worker_ref_id: string (nullable = true)\n",
            " |-- worker_title: string (nullable = true)\n",
            " |-- affected_from: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_employee.createOrReplaceTempView(\"employee\")\n",
        "df_titles.createOrReplaceTempView(\"titles\")"
      ],
      "metadata": {
        "id": "_vJMXe5iP6ok"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "source": [
        "spark.sql(\"\"\"\n",
        "    SELECT worker_id, first_name, last_name, best_paid_title, salary\n",
        "    FROM (\n",
        "        SELECT e.worker_id, e.first_name, e.last_name, t.worker_title AS best_paid_title, e.salary,\n",
        "               RANK() OVER (ORDER BY t.worker_title DESC) AS salary_rank\n",
        "        FROM employee e\n",
        "        JOIN titles t ON e.worker_id = t.worker_ref_id\n",
        "    ) ranked_employees\n",
        "    WHERE salary_rank = 1\n",
        "\"\"\").show()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seUTn7enUlqz",
        "outputId": "6ff98226-3ee3-4f6f-a9c1-41b249ef8a37"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+---------+---------------+------+\n",
            "|worker_id|first_name|last_name|best_paid_title|salary|\n",
            "+---------+----------+---------+---------------+------+\n",
            "|       10|     Helen|   Yellow|Senior Engineer| 16000|\n",
            "|        6|     David|    White|Senior Engineer| 16000|\n",
            "+---------+----------+---------+---------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wqBdBh_Qubf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}